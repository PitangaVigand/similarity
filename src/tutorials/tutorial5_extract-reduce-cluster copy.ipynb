{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ivpy import attach,show,montage,histogram,scatter,compose\n",
    "from ivpy.extract import extract\n",
    "from ivpy.reduce import pca,tsne,umap\n",
    "from ivpy.cluster import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"/mnt/e/Tasks/similarity/Images/jpg/\"\n",
    "df = pd.read_csv(\"oxfordflower.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filename = [DIR+item for item in df.filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attach(df,'filename')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I included basic color features in oxfordflower.csv, to show off the plotting functions. But now we can extract those features ourselves with `extract()`. All you need to pass to extract is the image filepaths, and a keyword telling ivpy which feature to extract. Currently, the options are 'brightness', 'saturation', 'hue', 'entropy', 'std', 'contrast', 'dissimilarity', 'homogeneity', 'ASM', 'energy', 'correlation', 'neural', 'tags', or 'dmax'. Since we've already looked at the HSV properties, let's check out the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['entropy'] = extract('entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage(xcol='entropy',shape='circle',ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are better datasets for illustrating entropy, but by looking at the middle of the plot, we can see that low entropy images are \"simpler\" or more \"minimalist\", and the high entropy images at the outer edge are \"noisier\". I won't march through all of the examples, but entropy, standard deviation, contrast, dissimilarity, homogeneity, ASM, energy, and correlation are all texture properties derived from the gray-level co-occurrence matrix (GLCM). For more information, visit the scikit-image page: https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_glcm.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural nets are all the rage now, and a neural net measure of similarity can be a great starting point for exploring your image collections. Moreover, because the neural net extractor delivers a high-dimensional vector, rather than a single number, we can test out our dimension reduction and clustering algorithms. Ivpy's neural net vector is the output of the penultimate layer of ResNet50: https://arxiv.org/abs/1512.03385"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = extract('neural')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's normalize the vector space using extract.norm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ivpy.extract import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = norm(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's start by clustering in the high-dimensional space. Since there are 17 flower names, let's set the number of clusters to 17. If we pass no keyword argument for 'method', the method will be k-means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster_kmeans_17'] = cluster(X,k=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage(facetcol='cluster_kmeans_17')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad! Let's see how well this purely visual clustering accords with the actual flower names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score as adjrand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(zip(list(df.flowername.unique()),list(range(len(df.flowername.unique())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['flower_number'] = [d[item] for item in df.flowername]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjrand(df.flower_number,df.cluster_kmeans_17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adjusted rand score measures the similarity of two clusterings. A score of 1.0 means a perfect match, and random is about zero. So, 0.47 is not too bad! This means that there is some flower name signal in the purely visual data, but it does not provide a perfect discriminator. For fun, we could zoom into a heterogeneous cluster to see what's going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cluster_number in df.cluster_kmeans_17.unique():\n",
    "    tmp = df.flowername[df.cluster_kmeans_17==cluster_number]\n",
    "    n = len(tmp.unique())\n",
    "    print(cluster_number,\":\",n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at cluster 3. From the plot above, we can see it looks pretty visually unified, but there are 10 different flower names in there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage(pathcol=df.filename[df.cluster_kmeans_17==3],notecol=df.flowername[df.cluster_kmeans_17==3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah ok. In addition to daffodils, there are yellow tulips, sunflowers, cowslips, buttercups, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok that was fun. But now let's just look at all the images on the same plotting canvas, by reducing the 2048 dimensions of the ResNet50 vector down to 2. We can actually look at 3 different algorithms, and can make a triptych of plots with a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotlist = []\n",
    "for func in [pca,tsne,umap]:\n",
    "    df[['x','y']] = func(X,n_components=2)\n",
    "    plotlist.append(scatter('x','y',side=800,xbins=40,ybins=40,thumb=20))\n",
    "compose(*plotlist,ncols=3,border=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-SNE plot (middle) looks pretty interesting. Let's take a closer look. We will remove the gridding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['x','y']] = tsne(X)\n",
    "scatter('x','y',side=4000,thumb=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! We have some pretty clear flower neighborhoods here, and maybe have the very beginnings of a simple K-Nearest-Neighbors flower classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a note on the reducing functions: they all use the scikit-learn API, including keywords. Ivpy is really just a thin wrapper around scikit-learn's already concise API. Usually, these functions will default to 2 dimensions, but you must pass `n_components=2` to `pca()`; it's default is 1360."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdc030d2aff99b4e0b8022eb6d55fbfb90d55598a46a3401b28c91dfb1820d3f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('ivpy-8DFwxc5m': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
